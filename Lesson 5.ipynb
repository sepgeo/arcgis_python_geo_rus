{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats, special\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "\n",
    "# Прочитаем таблицу класса данных в таблицу\n",
    "fc_path = r'C:\\Projects\\geochem_python_lessons\\Lessons\\5 Correlation and Factor analysis\\Lesson_5.gdb\\soil_samples_100x20'\n",
    "fields = sorted(\n",
    "                [i.name for i in arcpy.ListFields(fc_path) \n",
    "                 if i.name not in ['Shape', 'Profile', 'Sample']]\n",
    "               )\n",
    "data = [i for i in arcpy.da.SearchCursor(fc_path, fields)]\n",
    "df = pd.DataFrame(data, columns = [i.replace('_', '') for i in fields]).set_index('OBJECTID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычислим коэффициент чувствительности\n",
    "\n",
    "include_list = [] # список для подходящих переменных\n",
    "\n",
    "total_rows = len(df) # общее количество переменных\n",
    "for col in df:\n",
    "    min_value = min(df[col]) # минимальное значение (предположение, что все элементы имеют замену < LOD)\n",
    "    sec_min_value = min(df.loc[df[col] != min_value, col]) # второе минимальное значение\n",
    "    k_sensitivity = (sum(df[col] == min_value) + sum(df[col] == sec_min_value)/2 ) / total_rows # коэффициент чувствительности\n",
    "    \n",
    "    # выбор\n",
    "    if k_sensitivity < 0.8:\n",
    "        print(f\"{col}: {k_sensitivity:.2f}\")\n",
    "        include_list.append(col)\n",
    "    else:\n",
    "        print(f\"{col}: {k_sensitivity:.2f} ИСКЛЮЧИТЬ\")\n",
    "print(f'\\nОбщее количество подходящих переменных: {len(include_list)}\\n\\nСписок: {include_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим нормальное распределение, нормализуем\n",
    "\n",
    "df_norm = df.loc[:, include_list].copy() # копия для нормализованных данных\n",
    "\n",
    "print(\"p-значения коэффициентов ассиметрии и эксцесса:\")\n",
    "for col in df_norm:\n",
    "    subset_data = df_norm[col].to_numpy() # выборка\n",
    "    \n",
    "    # вычислим коэффициенты асимметрии и эксцесса\n",
    "    skewness_coef = stats.skew(subset_data)\n",
    "    kurtosis_coef = stats.kurtosis(subset_data)\n",
    "    \n",
    "    # Определим коэффициенты стат.значимости\n",
    "    p_skewness = 2 * (1 - special.erf(np.abs(skewness_coef) / np.sqrt(2)))\n",
    "    p_kurtosis = 2 * (1 - special.erf(np.abs(kurtosis_coef - 3) / np.sqrt(24)))\n",
    "    \n",
    "    # Сверим\n",
    "    if p_skewness < 0.05 or p_kurtosis < 0.05:\n",
    "        print(f\"{col}: {p_skewness:.2f}, {p_kurtosis:.2f} Предполагаем ЛОГнормальное распределение\")\n",
    "        df_norm[col] = np.log(subset_data) # логарифмирование для любителей логарифмов\n",
    "        #df_norm[col], _ = stats.boxcox(subset_data) # преобразование box-cox\n",
    "    else:\n",
    "        print(f\"{col}: {p_skewness:.2f}, {p_kurtosis:.2f} Предполагаем нормальное распределение\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График матрицы коэффициентов корреляции (простой)\n",
    "def custom_corr_matrix(df, method = 'pearson'):\n",
    "    \"\"\"\n",
    "    Функция создаёт график матрицы коэффициентов корреляции\n",
    "    \n",
    "    method - str: pearson, kendall, spearman\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(10/2.54, 10/2.54), constrained_layout=True)\n",
    "    corrMatrix = df.corr(method = method)\n",
    "    #sns.set_context(\"paper\", rc={\"axes.labelsize\":12})\n",
    "    sns.heatmap(corrMatrix,\n",
    "                fmt='.1f',\n",
    "                #mask = corrMatrix.abs() < 0.2,\n",
    "                vmin= -1, vmax=1, center= 0,\n",
    "                cmap = 'bwr',#sns.diverging_palette(220, 20, n=200),\n",
    "                linewidths=0.2, linecolor='grey', yticklabels=1, xticklabels=1,\n",
    "                annot=True, annot_kws={\"fontsize\":8}, cbar=False)\n",
    "    \n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "custom_corr_matrix(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b65030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График матрицы коэффициентов корреляции (с кластеризацией)\n",
    "def custom_corr_matrix_v2(df, method = 'pearson'):\n",
    "    \"\"\"\n",
    "    Функция создаёт график матрицы коэффициентов корреляции c кластеризацией\n",
    "    \n",
    "    method - str: pearson, kendall, spearman\n",
    "    \"\"\"\n",
    "    g = sns.clustermap(\n",
    "                        df.corr(method = method),\n",
    "                        figsize=(16/2.54, 14/2.54),\n",
    "                        method = 'complete', \n",
    "                        cmap   = 'seismic',\n",
    "                        annot  = True,\n",
    "                        fmt='.1f',\n",
    "                        #mask = df.corr().abs() < 0.2,\n",
    "                        vmin= -1, vmax=1, center= 0,\n",
    "                        linewidths=0.2, linecolor='grey', yticklabels=1, xticklabels=1,\n",
    "                        annot_kws = {'size': 10})\n",
    "    plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "custom_corr_matrix_v2(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим количество факторов\n",
    "\n",
    "pca = PCA() # создаём экземпляр класса PCA с параметрами метода\n",
    "df_stand = pd.DataFrame( StandardScaler().fit_transform(df_norm), columns = df_norm.columns)\n",
    "_ = pca.fit_transform(df_stand) # делаем PCA на данных\n",
    "\n",
    "#  Точка перегиба по второй производной\n",
    "features_list = np.arange(df_stand.shape[1])\n",
    "n_factors = np.diff(pca.explained_variance_ratio_,2).argmin()+1\n",
    "\n",
    "# Построение графика каменистой осыпи\n",
    "def scree_plot(features_list, pca, n_factors):\n",
    "    fig = plt.figure(figsize=(16/2.54, 10/2.54), constrained_layout=True)\n",
    "    plt.plot(features_list+1, pca.explained_variance_, 'ro-', linewidth=2)\n",
    "    plt.plot(n_factors, pca.explained_variance_[n_factors-1], 'o', markersize=12)\n",
    "    total_explained_variance = np.sum(pca.explained_variance_ratio_[0:n_factors-1])\n",
    "    plt.text(n_factors+0.5,\n",
    "             pca.explained_variance_[n_factors-1]*1.10,\n",
    "             f\"Количество факторов = {n_factors}. σ\\u00b2 {total_explained_variance:.2%}\"\n",
    "             )\n",
    "    plt.axhline(y=1)\n",
    "    plt.title('График каменистой осыпи')\n",
    "    plt.xlabel('Главные компоненты')\n",
    "    plt.ylabel('Объясненная дисперсия')\n",
    "    plt.show()\n",
    "\n",
    "scree_plot(features_list, pca, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b12e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 5 # если нужно в ручную изменить количество факторов\n",
    "scree_plot(features_list, pca, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb70df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собственно факторный анализ\n",
    "fa = FactorAnalysis(n_components=n_factors, rotation='quartimax') # 'varimax', 'quartimax'\n",
    "fa.fit(df_stand)\n",
    "\n",
    "# Проверка общностей\n",
    "communalities_calc = np.sum(np.transpose(fa.components_)**2,axis=1)\n",
    "communalities = pd.DataFrame(communalities_calc, index=df_stand.columns)\n",
    "features_comm = list(communalities[communalities[0] > 0.2].index)\n",
    "features_low =  list(communalities[communalities[0] < 0.2].index)\n",
    "print('Количество переменных с общностью >0.2: {}'.format(len(features_comm)))\n",
    "print(f'Элементы описанные удовлетворительно: {features_comm}')\n",
    "print(f'Элементы описанные неудовлетворительно: {features_low}')\n",
    "\n",
    "# Таблица нагрузок\n",
    "fa_loading_matrix = pd.DataFrame(\n",
    "                                np.transpose(fa.components_),\n",
    "                                columns = [f'FA{i}' for i in range(1, n_factors+1)],\n",
    "                                index= df_stand.columns\n",
    "                                )\n",
    "factor_names = fa_loading_matrix.columns\n",
    "fa_loading_matrix['Высшая_нагрузка'] = fa_loading_matrix.abs().idxmax(axis=1)\n",
    "fa_loading_matrix = fa_loading_matrix.sort_values('Высшая_нагрузка')\n",
    "# Исключим переменные с низкой общностью\n",
    "fa_loading_matrix = fa_loading_matrix.drop(features_low)\n",
    "\n",
    "# Таблица факторных нагрузок\n",
    "def plot_factor_scores(fa_loading_matrix):\n",
    "    fig = plt.figure(figsize=(16/2.54, 10/2.54), constrained_layout=True)\n",
    "    \n",
    "    map_mask = fa_loading_matrix.drop('Высшая_нагрузка', axis=1).abs() < 0.32\n",
    "\n",
    "    plot = sns.heatmap(\n",
    "                        fa_loading_matrix.drop('Высшая_нагрузка', axis=1),\n",
    "                        fmt = '.2f', \n",
    "                        mask = map_mask,\n",
    "                        vmin = -1, vmax = 1, center = 0, \n",
    "                        cmap = sns.diverging_palette(220, 20, n=200), \n",
    "                        linewidths = 0.2, linecolor = 'grey', yticklabels = 1,\n",
    "                        annot = True, annot_kws = {\"fontsize\":11}, cbar = False\n",
    "                        )\n",
    "\n",
    "    plot.set_yticklabels(\n",
    "                        plot.get_yticklabels(), \n",
    "                        rotation = 0, \n",
    "                        horizontalalignment = 'right',\n",
    "                        fontweight = 'light',\n",
    "                        fontsize = 'large'\n",
    "                        )\n",
    "    plt.show()\n",
    "\n",
    "plot_factor_scores(fa_loading_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Факторные значения\n",
    "fa_scores = pd.DataFrame(fa.transform(df_stand), columns = factor_names)\n",
    "fa_scores = fa_scores.set_index(df.index)\n",
    "fa_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим полные названия факторов\n",
    "\n",
    "def get_sub(string):\n",
    "    \"\"\"Функция перевода текста в нижний регистр\"\"\"\n",
    "    \n",
    "    normal = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+-=()\"\n",
    "    sub_s = \"ₐ₈CDₑբGₕᵢⱼₖₗₘₙₒₚQᵣₛₜᵤᵥwₓᵧZₐ♭꜀ᑯₑբ₉ₕᵢⱼₖₗₘₙₒₚ૧ᵣₛₜᵤᵥwₓᵧ₂₀₁₂₃₄₅₆₇₈₉₊₋₌₍₎\"\n",
    "    res = string.maketrans(''.join(normal), ''.join(sub_s))\n",
    "    return string.translate(res)\n",
    "\n",
    "def get_full_factor_name(col, loadings):\n",
    "    \"\"\"Функция для составления полного названия фактора из номера фактора и нагрузок\"\"\"\n",
    "    \n",
    "    # значимые нагрузки > 0.32\n",
    "    idx = loadings.abs() > 0.32\n",
    "    loadings_sub = loadings.loc[idx]\n",
    "    \n",
    "    # упорядочим строки по абсолютным значениям нагрузок\n",
    "    desired_order = loadings_sub.abs().sort_values(ascending=False).index \n",
    "    \n",
    "    # переведём нагрузки в строки\n",
    "    loadings_subset = loadings_sub.reindex(desired_order).round(2).astype(str)\n",
    "    \n",
    "    # объединим элементы и нагрузки\n",
    "    strings_list = [name+get_sub(value) for name, value in loadings_subset.items()]\n",
    "    \n",
    "    # составим полное название фактора\n",
    "    factor_long_name = col + ' ' + ', '.join(strings_list)\n",
    "    \n",
    "    return factor_long_name\n",
    "\n",
    "# проверим полные названия факторов\n",
    "for col in fa_scores:\n",
    "    print(get_full_factor_name(col, fa_loading_matrix[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновим класс данных\n",
    "\n",
    "# Добавим столбцы в таблицу\n",
    "for col in fa_scores:    \n",
    "    \n",
    "    # получим полное название фактора\n",
    "    alias_name = get_full_factor_name(col, fa_loading_matrix[col])\n",
    "    \n",
    "    # Проверми если столбец существует\n",
    "    current_fields = [i.name for i in arcpy.ListFields(fc_path)]\n",
    "    if col not in current_fields:\n",
    "        # Добавим новый столбец\n",
    "        arcpy.management.AddField(in_table =  fc_path, \n",
    "                                  field_name = col, \n",
    "                                  field_type = 'FLOAT',\n",
    "                                  field_scale = 3, \n",
    "                                  field_alias = alias_name\n",
    "                                  )\n",
    "        print(f'{col} - {alias_name} поле было добавлено')\n",
    "    else:\n",
    "        # изменим псевдоним\n",
    "        arcpy.management.AlterField(in_table = fc_path, field = col, new_field_alias = alias_name)\n",
    "        print(f'{col} - {alias_name} псевдоним поля был изменён')\n",
    "    \n",
    "# Добавим значения факторов в таблицу\n",
    "fields = ['OID@'] + list(fa_scores.columns)\n",
    "with arcpy.da.UpdateCursor(fc_path, fields) as cur:\n",
    "    for row in cur:\n",
    "        row[1:] = fa_scores.loc[row[0], :].to_list() \n",
    "        cur.updateRow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
